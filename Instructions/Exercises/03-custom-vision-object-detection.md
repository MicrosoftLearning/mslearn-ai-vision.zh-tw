---
lab:
  title: 使用 Azure AI 自訂視覺，偵測影像中的物件
---

# 使用 Azure AI 自訂視覺，偵測影像中的物件

在此練習中，您將使用自訂視覺服務來定型「物件偵測」** 模型，以偵測並找出影像中的三種水果 (蘋果、香蕉和柳橙)。

## 複製本課程的存放庫

如果您已將 **mslearn-ai-vision** 程式碼存放庫複製到您正在此實驗室使用的環境，請在 Visual Studio Code 中予以開啟；否則，請依照下列步驟立即進行複製。

1. 啟動 Visual Studio Code。
2. 開啟選擇區 (SHIFT+CTRL+P) 並執行 **Git：複製 ** 命令，將 `https://github.com/MicrosoftLearning/mslearn-ai-vision` 存放庫複製到本機資料夾 (哪個資料夾無關緊要)。
3. 複製存放庫後，請在 Visual Studio Code 中開啟此資料夾。
4. 等候其他檔案安裝以支援存放庫中的 C# 程式碼專案。

    > **注意**：如果系統提示您新增必要的資產來組建和偵錯，請選取 [現在不要]****。

## 建立自訂視覺資源

如果您的 Azure 訂用帳戶中已有可用來訓練、預測的**自訂視覺**資源，即可使用它們，或可在本練習裡的現有多種服物務帳戶中使用。 如果沒有，請使用下列指示來建立。

> **備註**：如果使用到多種服務資源，那麼訓練、預測的金鑰和端點就會一樣。

1. 在新的瀏覽器索引標籤中，開啟 Azure 入口網站 (位於 `https://portal.azure.com`)，使用與您的 Azure 訂用帳戶相關聯的 Microsoft 帳戶進行登入。
2. 選取 [&65291;建立資源]**** 按鈕，搜尋*自訂視覺*，然後使用下列設定建立**自訂視覺**資源：
    - **建立選項**：兩者
    - **訂用帳戶**：您的 Azure 訂用帳戶**
    - **資源群組**：*選擇或建立資源群組 (如果您使用受限制的訂用帳戶，則您可能沒有建立新資源群組的權限 - 請使用所提供的資源群組)*
    - **區域**：*選擇任何可用的區域*
    - **名稱**：輸入唯一名稱**
    - **定型定價層**：F0
    - **預測定價層**：F0

    > **注意**：若您的訂用帳戶中已經有 F0 自訂視覺服務，請為這一個選取 [S0]****。

3. 等候資源建立，然後檢視部署詳細資料，並注意已佈建兩個自訂視覺資源；一個用於定型，另一個用於預測 (以 **-Prediction** 尾碼顯示)。 您可以透過導覽到建立它們的資源群組來檢視這些資源。

> **重要**：每個資源都有自己的*端點*和*金鑰*，可用來管理來自程式碼的存取。 若要定型影像分類模型，您的程式碼必須使用*定型*資源 (搭配其端點和金鑰)；而若要使用定型的模型來預測影像類別，您的程式碼必須使用*預測*資源 (搭配其端點和金鑰)。

## 建立自訂視覺專案

若要訓練物件偵測模型，您必須根據訓練資源來建立自訂視覺專案。 為此，您將使用自訂視覺入口網站。

1. 在新的瀏覽器索引標籤中，開啟位於 `https://customvision.ai` 的自訂視覺入口網站，並使用與您的 Azure 訂用帳戶相關聯的 Microsoft 帳戶登入。
2. 建立包含下列設定的新專案：
    - **名稱**：偵測水果
    - **描述**：針對水果的物件偵測。
    - **資源**：*您先前建立的自訂視覺資源*
    - **專案類型**：物件偵測
    - **網域**：一般
3. 等候專案建立並在瀏覽器中開啟。

## 新增並標記影像

若要訓練物件偵測模型，您必須上傳影像 (其包含想要模型識別的類別)，並加以標記來表示每個物件執行個體的周框方塊。

1. 在 Visual Studio Code 中，於您複製存放庫的 **Labfiles/03-object-detection/training-images** 資料夾中檢視定型影像。 此資料夾包含水果的影像。
2. 在自訂視覺入口網站，您的物件偵測專案中，選取 [新增影像] **** 並上傳已擷取資料夾中的影像。
3. 影像上傳完成後，選取第一個加以開啟。
4. 將滑鼠游標暫留在影像中的任一物件上，直到如下影像顯示自動偵測的區域。 然後選取物件，如有必要，請調整區域大小以將其環繞。

    ![物件的預設區域](../media/object-region.jpg)

    或者，您可以簡單地在物件周圍拖曳以建立區域。

5. 當區域環繞物件時，新增具有適當物件類型 (「蘋果」**、「香蕉」** 或「柳橙」**) 的新標籤，如下所示：

    ![影像中一個已標記的物件](../media/object-tag.jpg)

6. 選取並標記影像中的每個其他物件，調整區域大小並視需要新增標籤。

    ![影像中兩個已標記的物件](../media/object-tags.jpg)

7. 使用右側的 **>** 連結移至下一個影像，並標記其物件。 然後，只需繼續處理整個影像集合並標記每個蘋果、香蕉與柳橙即可。

8. 當您完成最後影像標記時，請先關閉 [ **影像細節** 資料] 編輯器。 請在 [**訓練影像]** 頁面上的 [標記 **] 下方**，選取 **[** 已標記]，即可查看所有已標記的影像：

![專案中已標記的影像](../media/tagged-images.jpg)

## 使用定型 API 來上傳影像

您可以使用自訂視覺入口網站中的 UI 標記影像，但許多 AI 開發小組會使用其他工具，以便產生檔案，其中包含影像中的標記、物件區域等相關資訊。 在這類案例中，您可以使用自訂視覺定型 API 將已標記的影像上傳至專案。

> **注意**：在此練習中，您可以選擇從 **C#** 或 **Python** SDK 使用 API。 在下列步驟中，執行適合您慣用語言的動作。

1. 按一下自訂視覺入口網站中 [定型影像]**** 頁面右上方的 [設定]** (&#9881;) 圖示，以檢視專案設定。
2. 在左側的 [一般]**** 之下，記下可唯一識別此專案的 [專案識別碼]****。
3. 在右側的 [資源]**** 之下，注意已顯示金鑰和端點。 這些是*定型*資源的詳細資料 (您也可以在 Azure 入口網站中檢視資源以取得這項資訊)。
4. 在 Visual Studio Code 中，於 [Labfiles/03-object-detection]**** 資料夾之下，根據您的語言喜好設定，展開 [C-Sharp]**** 或 [Python]**** 資料夾。
5. 以滑鼠右鍵按一下 **train-detector** 資料夾，然後開啟整合式終端機。 然後針對您的語言喜好設定執行適當的命令，以安裝自訂視覺定型套件：

**C#**

```
dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0
```

**Python**

```
pip install azure-cognitiveservices-vision-customvision==3.1.1
```

6. 檢視 **train-detector** 資料夾的內容，並注意其中包含組態設定的檔案：
    - **C#**：appsettings.json
    - **Python**：.env

    開啟組態檔並更新其中包含的組態值，以反映您自訂視覺「定型」** 資源的端點和金鑰，以及您先前建立之物件偵測專案的專案識別碼。 儲存您的變更。

7. 在 **train-detector** 資料夾中，開啟 **tagged-images.json**並檢查其所包含的 JSON。 JSON 會定義一份影像清單，每個影像都包含一或多個已標記的區域。 每個已標記的區域都包含標記名稱，以及含有已標記物件的週框方塊的頂端和左座標及寬度和高度維度。

    > **注意**：此檔案中的座標和維度表示影像上的相對點。 例如，「高度」** 值為 0.7 表示影像高度 70% 的方塊。 有些標記工具會產生其他格式的檔案，其中座標和維度值代表像素、英吋或其他測量單位。

8. 請注意，**train-detector** 資料夾包含子資料夾，其中儲存 JSON 檔案所參考的影像檔案。

9. 請注意，**text-analysis** 資料夾包含用戶端應用程式的程式碼檔案：

    - **C#**：Program.cs
    - **Python**：train-detector.py

    開啟程式碼檔案並檢閱其所包含的程式碼，並注意下列詳細資料：
    - 從您安裝的套件匯入命名空間
    - **Main** 函式會擷取組態設定，並使用金鑰和端點來建立已驗證的 **CustomVisionTrainingClient**，然後搭配專案識別碼使用以建立專案的 **Project** 參考。
    - **Upload_Images**函式會從 JSON 檔案擷取已標記的區域資訊，並用以建立具有區域的影像批次，然後再上傳至專案。

10. 傳回 **train-detector** 資料夾的整合式終端機，然後輸入下列命令來執行程式：
    
    **C#**
    
    ```
    dotnet run
    ```
    
    **Python**
    
    ```
    python train-detector.py
    ```
    
11. 等候程式結束。 然後返回瀏覽器，並在自訂視覺入口網站中檢視專案的 [定型影像]**** 頁面 (視需要重新整理瀏覽器)。
12. 確認已將一些已標記的新影像新增至專案。

## 訓練並測試模型

現在您已經在專案中標記影像，可開始訓練模型。 您

1. 在自訂視覺專案中，按一下 [訓練]**** 以使用已標記的影像來訓練物件偵測模型。 選取 [Quick Training] (快速訓練)**** 選項。
2. 等待訓練完成 (這可能需要十分鐘左右)，然後檢閱精確度**、重新叫用** 和對應** 效能計量，這些計量測量分類模型的預測正確性，各項計量應該都較高。
3. 在頁面的右上方，按一下 [Quick Test] (快速測試)****，然後在 [影像 URL]**** 方塊中，輸入 `https://aka.ms/apple-orange` 並檢視所產生的預測。 然後關閉 [Quick Test] (快速測試)**** 視窗。

## 發佈物件偵測模型

您現在已準備好發佈已定型的模型，以便從用戶端應用程式使用該模型。

1. 在自訂視覺入口網站的 [效能]**** 頁面上，按一下 [&#128504; 發佈]**** 以發佈具有下列設定的已定型模型：
    - **模型名稱**：fruit-detector
    - **預測資源**：*您先前建立的**預測**資源，其結尾是 "-Prediction" (<u>不是</u>定型資源)*。
2. 在 [專案設定] **** 頁面的左上方，按一下*專案資源庫* (&#128065;) 圖示以返回自訂視覺入口網站首頁，現在您的專案已在其中列出。
3. 在自訂視覺入口網站首頁的右上方，按一下設定 ** (&#9881;) 圖示以檢視自訂視覺服務的設定。 然後，在 [資源]**** 之下，尋找以 "-Prediction" 結尾的*預測*資源 (<u>不是</u>定型資源) 來判斷其**金鑰**和**端點**值 (您也可在Azure 入口網站中檢視資源以取得這項資訊)。

## 從用戶端應用程式使用影像分類器

既然您已發佈影像分類模型，即可從用戶端應用程式使用。 同樣地，您可以選擇使用 **C#** 或 **Python**。

1. 在 Visual Studio Code 中，瀏覽至 **Labfiles/03-object-detection** 資料夾，並在您慣用語言 (**C-Sharp** 或 **Python**) 的資料夾中，展開 **test-detector** 資料夾。
2. 以滑鼠右鍵按一下 **test-detector** 資料夾，然後開啟整合式終端機。 然後輸入下列 SDK 特有命令來安裝自訂視覺預測套件：

**C#**

```
dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0
```

**Python**

```
pip install azure-cognitiveservices-vision-customvision==3.1.1
```

> **注意**：Python SDK 套件同時包含定型和預測套件，而且可能已經安裝。

3. 開啟用戶端應用程式的組態檔 (適用於 C# 的*appsettings.json* 或適用於 Python 的 *.env*)，並更新其中包含的組態值，以反映自訂視覺「預測」** 資源的端點和金鑰、物件偵測專案的專案識別碼，以及已發佈模型的名稱 (應該是 *fruit-detector*)。 儲存您的變更。
4. 開啟用戶端應用程式的程式碼檔案 (適用於 C# 的 *Program.cs*，適用於 Python 的 *test-detector.py*)，並檢閱其所包含的程式碼，並注意下列詳細資料：
    - 從您安裝的套件匯入命名空間
    - **Main** 函式會擷取組態設定，並使用金鑰和端點來建立已驗證的 **CustomVisionPredictionClient**。
    - 預測用戶端物件用於取得 **produce.jpg** 影像的物件偵測預測，並在要求中指定專案識別碼和模型名稱。 預測的標記區域接著會繪製在影像上，結果會儲存為 **output.jpg**。
5. 傳回 **test-detector** 資料夾的整合式終端機，然後輸入下列命令來執行程式：

**C#**

```
dotnet run
```

**Python**

```
python test-detector.py
```

6. 程式完成之後，檢視所產生的 **output.jpg** 檔案，以查看影像中偵測到的物件。

## 其他相關資訊

如需使用自訂視覺服務進行物件偵測的詳細資訊，請參閱[自訂視覺文件](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/)。
